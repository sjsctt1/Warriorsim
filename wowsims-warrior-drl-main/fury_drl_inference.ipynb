{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.tune.registry import register_env\n",
    "from fury_sim_env import FurySimEnv\n",
    "from gymnasium import make\n",
    "from gymnasium.envs.registration import register\n",
    "from gymnasium.wrappers import FrameStack\n",
    "from fury import *\n",
    "\n",
    "spell_id_lists = {\n",
    "        '0' : \"Melee\",\n",
    "        '23881' : \"Bloodthirst\",\n",
    "        '1680' : \"Whirlwind\",\n",
    "        '47475' : \"Slam\",\n",
    "        '47450' : \"Heroic Strike\",\n",
    "        '47471' : \"Execute\",\n",
    "        '12867': \"Deep Wounds\",\n",
    "        '12292' : \"Death Wish\",\n",
    "        '1719' : \"Recklessness\",\n",
    "        '64382' : \"Shattering Throw\",\n",
    "        '54758' : \"Engi Gloves\",\n",
    "        '2457' : \"Battle Stance\",\n",
    "        '2458' : \"Berserker Stance\",\n",
    "        '2687' : 'Bloodrage',\n",
    "        '2825' : 'Bloodlust',\n",
    "        '47465': 'Rend',\n",
    "        '7384': 'Overpower',\n",
    "        '44949': 'Whirlwind OH',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Fury Raid Sim Request JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open('data/fury-human-bis-p3.json')\n",
    "settings = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set environment and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def reset():\n",
    "    wowsims.new(json.dumps(settings).encode('utf-8'))\n",
    "\n",
    "\n",
    "# Iterations are currently capped at 3000\n",
    "iterations = settings['simOptions']['iterations']\n",
    "\n",
    "duration = settings['encounter']['duration']\n",
    "reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default sim agent\n",
    "Default sim agent is the hardcoded agent from the sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average DPS: 11891.96688184432\n"
     ]
    }
   ],
   "source": [
    "settings['simOptions']['interactive'] = False\n",
    "damages = np.array([])\n",
    "\n",
    "for i in range(iterations):\n",
    "    reset()\n",
    "    while not wowsims.step():\n",
    "        pass\n",
    "    totalDamage = wowsims.getDamageDone()\n",
    "    damages = np.append(damages, totalDamage)\n",
    "\n",
    "print(f'Average DPS: {damages.mean() / duration}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melee: [1, 1, 1, 2, 9, 77]\n",
      "Death Wish: [2]\n",
      "Deep Wounds: [133]\n",
      "Whirlwind: [16]\n",
      "Recklessness: [1]\n",
      "Bloodthirst: [33]\n",
      "Battle Stance: [9]\n",
      "Berserker Stance: [9]\n",
      "Bloodrage: [4]\n",
      "Bloodlust: [1]\n",
      "Whirlwind OH: [16]\n",
      "Heroic Strike: [68]\n",
      "Rend: [4]\n",
      "Execute: [8]\n",
      "Slam: [19]\n",
      "Engi Gloves: [3]\n",
      "Shattering Throw: [1]\n",
      "Overpower: [5]\n"
     ]
    }
   ],
   "source": [
    "settings['simOptions']['interactive'] = False\n",
    "\n",
    "reset()\n",
    "while not wowsims.step():\n",
    "    pass\n",
    "    \n",
    "    \n",
    "cast_metrics = wowsims.getSpellMetrics()\n",
    "\n",
    "for spell_id, metrics in cast_metrics.items():\n",
    "    try:\n",
    "        spell_name = spell_id_lists[spell_id]\n",
    "    except KeyError as key:\n",
    "        spell_name = key\n",
    "    print(f\"{spell_name}: {[metric['Casts'] for metric in metrics]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained PPO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 10:00:36,713\tINFO worker.py:1625 -- Started a local Ray instance.\n",
      "2023-05-09 10:00:42,653\tWARNING checkpoints.py:109 -- No `rllib_checkpoint.json` file found in checkpoint directory C:\\Users\\sjsct\\Downloads\\wowsims-warrior-drl-main (1)\\wowsims-warrior-drl-main\\models\\bloodsurge-reward-0.5\\PPO\\PPO_FurySimEnv_5d73b_00000_0_2023-05-05_17-04-03\\checkpoint_002849\\.! Trying to extract checkpoint info from other files found in that dir.\n",
      "2023-05-09 10:00:42,657\tWARNING algorithm_config.py:635 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "2023-05-09 10:00:42,674\tINFO trainable.py:913 -- Restored on 127.0.0.1 from checkpoint: C:\\Users\\sjsct\\Downloads\\wowsims-warrior-drl-main (1)\\wowsims-warrior-drl-main\\models\\bloodsurge-reward-0.5\\PPO\\PPO_FurySimEnv_5d73b_00000_0_2023-05-05_17-04-03\\checkpoint_002849\n",
      "2023-05-09 10:00:42,675\tINFO trainable.py:922 -- Current state after restoring: {'_iteration': 2849, '_timesteps_total': None, '_time_total': 18387.5619328022, '_episodes_total': 100029}\n"
     ]
    }
   ],
   "source": [
    "config = PPOConfig()\\\n",
    "            .rollouts(num_rollout_workers=1)\n",
    "\n",
    "\n",
    "register(id=\"FurySimEnv\", entry_point=\"fury_sim_env:FurySimEnv\")\n",
    "env = make(\"FurySimEnv\")\n",
    "# env_creator = lambda config: FrameStack(env, num_stack=5)\n",
    "env_creator = lambda config: FurySimEnv(...)\n",
    "register_env(\"FurySimEnv\", env_creator=env_creator)\n",
    "env = FrameStack(env, num_stack=5)\n",
    "\n",
    "algorithm = config.build(env=\"FurySimEnv\")\n",
    "env.spec.max_episode_steps = 10000\n",
    "algorithm.restore(\"C:\\\\Users\\\\sjsct\\\\Downloads\\\\wowsims-warrior-drl-main (1)\\\\wowsims-warrior-drl-main\\\\models\\\\bloodsurge-reward-0.5\\\\PPO\\\\PPO_FurySimEnv_5d73b_00000_0_2023-05-05_17-04-03\\\\checkpoint_002849\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PPO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=60456)\u001b[0m 2023-05-09 10:00:42,600\tWARNING env.py:155 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x120 and 24x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m state_out \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m terminated:\n\u001b[1;32m---> 14\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_single_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     16\u001b[0m     debug_logs\u001b[38;5;241m.\u001b[39mappend(info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdebug log\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:1595\u001b[0m, in \u001b[0;36mAlgorithm.compute_single_action\u001b[1;34m(self, observation, state, prev_action, prev_reward, info, input_dict, policy_id, full_fetch, explore, timestep, episode, unsquash_action, clip_action, unsquash_actions, clip_actions, **kwargs)\u001b[0m\n\u001b[0;32m   1587\u001b[0m     action, state, extra \u001b[38;5;241m=\u001b[39m policy\u001b[38;5;241m.\u001b[39mcompute_single_action(\n\u001b[0;32m   1588\u001b[0m         input_dict\u001b[38;5;241m=\u001b[39minput_dict,\n\u001b[0;32m   1589\u001b[0m         explore\u001b[38;5;241m=\u001b[39mexplore,\n\u001b[0;32m   1590\u001b[0m         timestep\u001b[38;5;241m=\u001b[39mtimestep,\n\u001b[0;32m   1591\u001b[0m         episode\u001b[38;5;241m=\u001b[39mepisode,\n\u001b[0;32m   1592\u001b[0m     )\n\u001b[0;32m   1593\u001b[0m \u001b[38;5;66;03m# Individual args.\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1595\u001b[0m     action, state, extra \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_single_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprev_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprev_reward\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_reward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1600\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepisode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepisode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1604\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1606\u001b[0m \u001b[38;5;66;03m# If we work in normalized action space (normalize_actions=True),\u001b[39;00m\n\u001b[0;32m   1607\u001b[0m \u001b[38;5;66;03m# we re-translate here into the env's action space.\u001b[39;00m\n\u001b[0;32m   1608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unsquash_action:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\policy\\policy.py:545\u001b[0m, in \u001b[0;36mPolicy.compute_single_action\u001b[1;34m(self, obs, state, prev_action, prev_reward, info, input_dict, episode, explore, timestep, **kwargs)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m episode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    543\u001b[0m     episodes \u001b[38;5;241m=\u001b[39m [episode]\n\u001b[1;32m--> 545\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_actions_from_input_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSampleBatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepisodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;66;03m# Some policies don't return a tuple, but always just a single action.\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;66;03m# E.g. ES and ARS.\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\policy\\torch_policy_v2.py:522\u001b[0m, in \u001b[0;36mTorchPolicyV2.compute_actions_from_input_dict\u001b[1;34m(self, input_dict, explore, timestep, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;66;03m# Calculate RNN sequence lengths.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m seq_lens \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    513\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m    514\u001b[0m         [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(state_batches[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    520\u001b[0m )\n\u001b[1;32m--> 522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_action_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_lens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestep\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\utils\\threading.py:24\u001b[0m, in \u001b[0;36mwith_lock.<locals>.wrapper\u001b[1;34m(self, *a, **k)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m---> 24\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_lock\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\policy\\torch_policy_v2.py:1141\u001b[0m, in \u001b[0;36mTorchPolicyV2._compute_action_helper\u001b[1;34m(self, input_dict, state_batches, seq_lens, explore, timestep)\u001b[0m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1140\u001b[0m     dist_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist_class\n\u001b[1;32m-> 1141\u001b[0m     dist_inputs, state_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_lens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(dist_class, functools\u001b[38;5;241m.\u001b[39mpartial)\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dist_class, TorchDistributionWrapper)\n\u001b[0;32m   1146\u001b[0m ):\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`dist_class` (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) not a TorchDistributionWrapper \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubclass! Make sure your `action_distribution_fn` or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`make_model_and_action_dist` return a correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistribution class.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dist_class\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1152\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\models\\modelv2.py:259\u001b[0m, in \u001b[0;36mModelV2.__call__\u001b[1;34m(self, input_dict, state, seq_lens)\u001b[0m\n\u001b[0;32m    256\u001b[0m         restored[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs_flat\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m input_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext():\n\u001b[1;32m--> 259\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestored\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_lens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_dict, SampleBatch):\n\u001b[0;32m    262\u001b[0m     input_dict\u001b[38;5;241m.\u001b[39maccessed_keys \u001b[38;5;241m=\u001b[39m restored\u001b[38;5;241m.\u001b[39maccessed_keys \u001b[38;5;241m-\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs_flat\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\models\\torch\\fcnet.py:146\u001b[0m, in \u001b[0;36mFullyConnectedNetwork.forward\u001b[1;34m(self, input_dict, state, seq_lens)\u001b[0m\n\u001b[0;32m    144\u001b[0m obs \u001b[38;5;241m=\u001b[39m input_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs_flat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_flat_in \u001b[38;5;241m=\u001b[39m obs\u001b[38;5;241m.\u001b[39mreshape(obs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hidden_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_last_flat_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logits(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_features) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logits \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_features\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_log_std:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\models\\torch\\misc.py:169\u001b[0m, in \u001b[0;36mSlimFC.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: TensorType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TensorType:\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x120 and 24x256)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(100):\n",
    "    observation, info = env.reset()\n",
    "    terminated = False\n",
    "    reward = 0\n",
    "    batch = []\n",
    "    dps_results = np.array([])\n",
    "    metrics_batch = []\n",
    "    debug_logs = []\n",
    "    debug_logs_batch = []\n",
    "    state_out = []\n",
    "    while not terminated:\n",
    "        action = algorithm.compute_single_action(observation)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        debug_logs.append(info['debug log'])\n",
    "    debug_logs_batch.append(debug_logs)\n",
    "    dps_results = np.append(dps_results, info['dps'])\n",
    "    metrics_batch.append(info['spell metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "median = np.argsort(dps_results)[len(dps_results)//2]\n",
    "print(f'Average DPS: {dps_results[median]}')\n",
    "\n",
    "cast_metrics = metrics_batch[median]\n",
    "for spell_id, metrics in cast_metrics.items():\n",
    "    # Only one target, so we can just take the first one\n",
    "    try:\n",
    "        spell_name = spell_id_lists[spell_id]\n",
    "    except KeyError as key:\n",
    "        spell_name = key\n",
    "    print(f\"{spell_name}: {[metric['Casts'] for metric in metrics]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "actions_id = {\n",
    "    0: \"Bloodthirst\", \n",
    "    1: \"Whirlwind\",\n",
    "    2: \"Slam\",\n",
    "    3: \"HeroicStrike\",\n",
    "    4: \"Execute\",\n",
    "    5: \"DeathWish\",\n",
    "    6: \"Recklessness\",\n",
    "    7: \"ShatteringThrow\",\n",
    "    8: \"Bloodrage\",\n",
    "    9: \"EngiGlove\",\n",
    "    10: \"Bloodlust\",\n",
    "    11: \"Idle\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(debug_logs_batch[median], columns=['Timestamp', 'Action', 'Successful Cast', 'Damage Done', 'Total Damage Done', 'Rage'])\n",
    "df['Action'] = df['Action'].map(actions_id)\n",
    "df['DPS'] = df['Total Damage Done'].div(df['Timestamp'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"debug_logs/debug_log_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spell Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset()\n",
    "Spells.register()\n",
    "Auras.register()\n",
    "TargetAuras.register()\n",
    "\n",
    "settings['simOptions']['interactive'] = True\n",
    "damages = np.array([])\n",
    "spell_metrics = []\n",
    "\n",
    "for i in range(1):\n",
    "    reset()\n",
    "    while not wowsims.step():\n",
    "        print(env.reset())\n",
    "        if wowsims.needsInput():\n",
    "            wowsims.trySpell(Spells.Bloodthirst)\n",
    "    totalDamage = wowsims.getDamageDone()\n",
    "    damages = np.append(damages, totalDamage)\n",
    "    spell_metrics.append(wowsims.getSpellMetrics())\n",
    "\n",
    "median = np.argsort(damages)[len(damages)//2]\n",
    "print(f'Average DPS: {damages[median] / duration}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings['simOptions']['interactive'] = True\n",
    "\n",
    "reset()\n",
    "while not wowsims.step():\n",
    "    pass\n",
    "cast_metrics = spell_metrics[median]\n",
    "for spell_id, metrics in cast_metrics.items():\n",
    "    try:\n",
    "        spell_name = spell_id_lists[spell_id]\n",
    "    except KeyError as key:\n",
    "        spell_name = key\n",
    "    print(f\"{spell_name}: {[metric['Casts'] for metric in metrics]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
